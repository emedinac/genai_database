# genai_database
 A growing collection of hands-on projects pushing the boundaries of GenAI: covering LLMs, agents, RAG variants, multimodal systems, and general generative models. Built to explore, test, and create at the edge of whatâ€™s possible.

## Why These Projects?
Over the past few months, Iâ€™ve been diving deep into the world of LLMs, agents, multimodal models, and tool integration, exploring different frameworks. To deepen my understanding and experiment with real-world applications, Iâ€™m building a series of practical, domain-specific systems ðŸ˜ƒ

## Content

|  Project  | Description  | Tech Stack  | Link |
|----------------------|-----------------------------------------------------------------|----------------------------------------|----------------------------------------------|
| 1. Prompt Benchmark Interface| A fully offline system leveraging Ollama to run local LLMs for experimenting with prompt engineering techniques, including Chain-of-Thought (CoT) and Self-Consistency on answering finance-related questions, particularly around stock market data and trends. This tool is designed for fast iteration, performance benchmarking, and analysis of prompt effectiveness in a domain where precision matters. Includes interactive parameter tuning (for the LLM and metrics), metrics visualization, and an experimentation workflow.   | LLMs, zero/few-shot (CoT,  Self-Consistency) propmt engineering, Gradio, Ollama, BeautifulSoup, Huggingface    | [View](https://github.com/emedinac/PromptBenchmarkInterface) |
| 2. Resume Analyzer |  This is a tool that uses Retrieval-Augmented Generation (RAG) to deeply understand candidate profiles. Instead of just matching keywords, it connects skills, experience, and qualifications to provide clear, explainable insights for hiring decisions. Perfect for recruiters, HR tech platforms, and anyone looking to evaluate talent more effectively. Assigning each a quantitative compatibility score and a qualitative explanation  | RAG, Langchain, FAISS, ChromaDB, LLMs (text generator and as-a-judge), Gradio  | [View](https://github.com/emedinac/ResumeAnalyzer)  |
| 3. LatentSync Enhanced with Optical Flow | This work is a proof of concept for multi-modal diffusion models, specifically a variant of [LatentSync](https://arxiv.org/abs/2412.09262) . The model's loss function is enhanced by integrating the optical flow technique, utilizing OpenCV, to improve mouth movement generation following a new audio input. This approach is inspired by the [VideoJAM](https://arxiv.org/abs/2502.02492) framework, which emphasizes joint appearance-motion representations to enhance motion coherence in video generation. The adaptation aims to synchronize audio features with video context, thereby improving temporal alignment and realism in the generated videos. This implementation was profiled in performance, and also adapted and evaluated exclusively using the HDTF dataset, a high-resolution audio-visual dataset designed for talking face generation. | Pytorch, Transformers, DeepCache, OpenCV | [View](https://github.com/emedinac/LatentSync)
| 4 LoRa LLM Finetunning for research (ongoing) | This project provides a framework for fine-tuning and evaluating LLMs (no APIs). It supports Low-Rank Adaptation (LoRA) and evaluates performance on research questionâ€“answering tasks, for arXiv and PubMed datasets, using standard metrics such as BLEU, ROUGE-L, and BERTScore. | PEFT, LoRa, Transformers Reinforcement Learning (TRL), Direct Preference Optimization (DPO), Huggingface, Q&A, summarization | [View](https://github.com/emedinac/Lora4Research)
| 5            |    | |
